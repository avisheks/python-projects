#!/bin/bash

HADOOP_PREFIX=/home/gs/hadoop/current
HADOOP=$HADOOP_PREFIX/bin/hadoop
HDFS=$HADOOP_PREFIX/bin/hadoop

CODE=/homes/$USER/python-hadoop-streaming/code
WORK=/homes/$USER/python-hadoop-streaming/work
DATA=/user/$USER/python-hadoop-streaming/data


job_queue=apg_devlarge_p4

set -x

run_cmd () {
    cmd=$1
    remove_outputs=$2
    echo "cmd=[$cmd]"
    eval $cmd
}

train_cmd_st="$HADOOP jar $HADOOP_PREFIX/share/hadoop/tools/lib/hadoop-streaming.jar \
    -Dmapreduce.job.queuename=$job_queue \
    -file    $CODE/mapper.py \
    -file    $CODE/reducer.py \
    -input   $DATA/*.txt \
    -output  $DATA/log \
    -mapper  $CODE/mapper.py \
    -reducer $CODE/reducer.py"
run_cmd "$train_cmd_st" "$CODE"                                

set +x
